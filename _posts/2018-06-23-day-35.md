---
title: Day 35
date: 2018-06-23 00:00:00 +00:00
layout: post
description: Human-AI Collaborations
---

## Polynomial Regression
(As an alternative to neural nets)
<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1010528773589164032">
    <blockquote placeholder><p lang="en" dir="ltr">Linear regressions with 2nd/3rd order polynomials were equal to or better than neural-nets (aka &#39;deep learning&#39;) in every data set they looked at. <a href="https://t.co/e0DTbtaKDa">https://t.co/e0DTbtaKDa</a></p>&mdash; David Baranger (@DABaranger) <a href="https://twitter.com/DABaranger/status/1010528773589164032?ref_src=twsrc%5Etfw">June 23, 2018</a></blockquote>
</amp-twitter>

## Removing Raindrops
<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1010618892245319680">
    <blockquote placeholder><p lang="en" dir="ltr">Automatically removing raindrops from an image. Useful for self-driving cars. Trains an attentive generative network using adversarial training. Learns about raindrop regions &amp; their surroundings, then generates focused on surroundings. <a href="https://t.co/y423rQkMdk">https://t.co/y423rQkMdk</a> <a href="https://t.co/e6FgxXyBSl">pic.twitter.com/e6FgxXyBSl</a></p>&mdash; Reza Zadeh (@Reza_Zadeh) <a href="https://twitter.com/Reza_Zadeh/status/1010618892245319680?ref_src=twsrc%5Etfw">June 23, 2018</a></blockquote>
</amp-twitter>

## Procedural Content Generation
<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1007047148633051137">
    <blockquote placeholder><p lang="en" dir="ltr">Our survey paper on Procedural Content Generation via Machine Learning (PCGML) is now officially published. We survey the nascent field of using ML to generate game content.<br><br>Available as early access on IEEE Xplore:<a href="https://t.co/AhfLbbUI4J">https://t.co/AhfLbbUI4J</a><br>And on ArXiv:<a href="https://t.co/riV6eYuCZ2">https://t.co/riV6eYuCZ2</a> <a href="https://t.co/xVno9TmS0b">pic.twitter.com/xVno9TmS0b</a></p>&mdash; Julian Togelius (@togelius) <a href="https://twitter.com/togelius/status/1007047148633051137?ref_src=twsrc%5Etfw">June 13, 2018</a></blockquote>
</amp-twitter>

## GrCAN
<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1010456118147944449">
    <blockquote placeholder><p lang="en" dir="ltr">GrCAN: Gradient Boost Convolutional Autoencoder with Neural Decision Forest. <a href="https://t.co/2eqxqwDfDX">https://t.co/2eqxqwDfDX</a> <a href="https://t.co/XN7hWfLjPa">pic.twitter.com/XN7hWfLjPa</a></p>&mdash; arxiv (@arxiv_org) <a href="https://twitter.com/arxiv_org/status/1010456118147944449?ref_src=twsrc%5Etfw">June 23, 2018</a></blockquote>
</amp-twitter>

## Collaborative Intelligence
<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1010535892585287681">
    <blockquote placeholder><p lang="en" dir="ltr">Human-AI Collaborations in 1,500 companies: training, explaining, interacting, and more: <a href="https://t.co/1JLaaOqoSE">https://t.co/1JLaaOqoSE</a> by <a href="https://twitter.com/pauldaugh?ref_src=twsrc%5Etfw">@pauldaugh</a></p>&mdash; Oren Etzioni (@etzioni) <a href="https://twitter.com/etzioni/status/1010535892585287681?ref_src=twsrc%5Etfw">June 23, 2018</a></blockquote>
</amp-twitter>

## Data Science vs. Statistics
<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1010533658757877762"
             data-conversation="none">
    <blockquote placeholder><p lang="en" dir="ltr">&quot;Data science vs. statistics: two cultures?&quot; A good review article collecting &amp; synthesizing all the diff opinions over the years. If someone should still ask what data science is about, that&#39;s the article to refer them to   <a href="https://t.co/TPy5UEHTfI">https://t.co/TPy5UEHTfI</a></p>&mdash; Sebastian Raschka (@rasbt) <a href="https://twitter.com/rasbt/status/1010533658757877762?ref_src=twsrc%5Etfw">June 23, 2018</a></blockquote>
</amp-twitter>

<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1010534029106581505"
             data-conversation="none">
    <blockquote placeholder><p lang="en" dir="ltr">Also has a good set of references on when/how the term was coined: <a href="https://t.co/fqssPaOb28">pic.twitter.com/fqssPaOb28</a></p>&mdash; Sebastian Raschka (@rasbt) <a href="https://twitter.com/rasbt/status/1010534029106581505?ref_src=twsrc%5Etfw">June 23, 2018</a></blockquote>
</amp-twitter>

## Tutorials
<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1010536270265634817">
    <blockquote placeholder><p lang="en" dir="ltr">This post about missing values in <a href="https://twitter.com/hashtag/julia?src=hash&amp;ref_src=twsrc%5Etfw">#julia</a> gives a good overview of the “software engineer’s null” vs. the “data scientist’s null” and why it matters. ht <a href="https://twitter.com/clarkfitzg?ref_src=twsrc%5Etfw">@clarkfitzg</a> <a href="https://t.co/AeDqym7Z6R">https://t.co/AeDqym7Z6R</a></p>&mdash; Jenny Bryan (@JennyBryan) <a href="https://twitter.com/JennyBryan/status/1010536270265634817?ref_src=twsrc%5Etfw">June 23, 2018</a></blockquote>
</amp-twitter>

<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1010585881013612545">
    <blockquote placeholder><p lang="en" dir="ltr">My Do More With R series of short screencasts so far:<br><br>* Interactive scatter plots<br>* dplyr&#39;s case_when<br>* test code with testthat<br>* easy <a href="https://twitter.com/hashtag/rstats?src=hash&amp;ref_src=twsrc%5Etfw">#rstats</a> dashboards<br>* <a href="https://twitter.com/rstudio?ref_src=twsrc%5Etfw">@RStudio</a> code snippets<a href="https://t.co/Ex2LlfjNwF">https://t.co/Ex2LlfjNwF</a><a href="https://twitter.com/hashtag/R4DS?src=hash&amp;ref_src=twsrc%5Etfw">#R4DS</a> <a href="https://t.co/wzNxW6m7X4">pic.twitter.com/wzNxW6m7X4</a></p>&mdash; Sharon Machlis (@sharon000) <a href="https://twitter.com/sharon000/status/1010585881013612545?ref_src=twsrc%5Etfw">June 23, 2018</a></blockquote>
</amp-twitter>

###  Recent Advances in Variational Inference
<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1010510020017049600">
    <blockquote placeholder><p lang="en" dir="ltr">A nice review article on recent advances in variational inference (C. Zhang, J. Butepage, H. Kjellstrom, S. Mandt): <a href="https://t.co/SLVVPAmchE">https://t.co/SLVVPAmchE</a> <a href="https://twitter.com/hashtag/MachineLearning?src=hash&amp;ref_src=twsrc%5Etfw">#MachineLearning</a></p>&mdash; Diana Cai (@dianarycai) <a href="https://twitter.com/dianarycai/status/1010510020017049600?ref_src=twsrc%5Etfw">June 23, 2018</a></blockquote>
</amp-twitter>

### Small n Correlations + p Values
<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1010147879627968512">
    <blockquote placeholder><p lang="en" dir="ltr">New post:<br>Small n correlations + p values = disaster<a href="https://t.co/KBgRHGCvLg">https://t.co/KBgRHGCvLg</a> <a href="https://t.co/mBe2oRb3Tk">pic.twitter.com/mBe2oRb3Tk</a></p>&mdash; Guillaume Rousselet (@robustgar) <a href="https://twitter.com/robustgar/status/1010147879627968512?ref_src=twsrc%5Etfw">June 22, 2018</a></blockquote>
</amp-twitter>

## Miscellaneous
<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1010564856909651968">
    <blockquote placeholder><p lang="en" dir="ltr">Dissolving the Fermi Paradox: why taking uncertainties into account makes the absence of aliens less weird, and why an empty sky doesn&#39;t foretell our doom. <a href="https://t.co/7C6g14Spbd">https://t.co/7C6g14Spbd</a> Popular FAQ: <a href="https://t.co/3a6piKhAmi">https://t.co/3a6piKhAmi</a></p>&mdash; Anders Sandberg (@anderssandberg) <a href="https://twitter.com/anderssandberg/status/1010564856909651968?ref_src=twsrc%5Etfw">June 23, 2018</a></blockquote>
</amp-twitter>

<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1010278944782708737">
    <blockquote placeholder><p lang="en" dir="ltr">Deep learning is useful because it enables us to create programs that we could not otherwise code by hand. But the space of programs you can learn via deep learning models is a minuscule slice of the space of programs that we may be interested in.</p>&mdash; François Chollet (@fchollet) <a href="https://twitter.com/fchollet/status/1010278944782708737?ref_src=twsrc%5Etfw">June 22, 2018</a></blockquote>
</amp-twitter>
