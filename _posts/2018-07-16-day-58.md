---
title: Day 58
date: 2018-07-16 00:00:00 +00:00
layout: post
description: AutoML
---

## Learning Resources
<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1018889268087779329">
    <blockquote placeholder><p lang="en" dir="ltr">Looks like my <a href="https://twitter.com/hashtag/SciPy2018?src=hash&amp;ref_src=twsrc%5Etfw">#SciPy2018</a> talk on AutoML is up on YouTube:<a href="https://t.co/5TaM6NDaCx">https://t.co/5TaM6NDaCx</a></p>&mdash; Randy Olson (@randal_olson) <a href="https://twitter.com/randal_olson/status/1018889268087779329?ref_src=twsrc%5Etfw">July 16, 2018</a></blockquote>
</amp-twitter>

<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1019086281031200768">
    <blockquote placeholder><p lang="en" dir="ltr">Video of my keynote at the International Joint Conference on Artificial intelligence, delivered yesterday in Stockholm. <a href="https://t.co/xxiQs1CTld">https://t.co/xxiQs1CTld</a></p>&mdash; Yann LeCun (@ylecun) <a href="https://twitter.com/ylecun/status/1019086281031200768?ref_src=twsrc%5Etfw">July 17, 2018</a></blockquote>
</amp-twitter>

<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1018933853124116480">
    <blockquote placeholder><p lang="en" dir="ltr">&quot;An Opinionated Introduction to AutoML and Neural Architecture Search&quot; by <a href="https://twitter.com/math_rachel?ref_src=twsrc%5Etfw">@math_rachel</a><a href="https://t.co/PyobFlVxxn">https://t.co/PyobFlVxxn</a> <a href="https://t.co/EzrcAnlnrq">pic.twitter.com/EzrcAnlnrq</a></p>&mdash; Jeremy Howard (@jeremyphoward) <a href="https://twitter.com/jeremyphoward/status/1018933853124116480?ref_src=twsrc%5Etfw">July 16, 2018</a></blockquote>
</amp-twitter>

<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1019088389079949317">
    <blockquote placeholder><p lang="en" dir="ltr">Slides from our <a href="https://twitter.com/hashtag/ACL2018?src=hash&amp;ref_src=twsrc%5Etfw">#ACL2018</a> tutorial on Neural Semantic Parsing with Alane Suhr, <a href="https://twitter.com/sriniiyer88?ref_src=twsrc%5Etfw">@sriniiyer88</a>, <a href="https://twitter.com/nlpmattg?ref_src=twsrc%5Etfw">@nlpmattg</a>, and <a href="https://twitter.com/LukeZettlemoyer?ref_src=twsrc%5Etfw">@LukeZettlemoyer</a> now online: <a href="https://t.co/YcMiXSlffW">https://t.co/YcMiXSlffW</a></p>&mdash; Pradeep Dasigi (@pdasigi) <a href="https://twitter.com/pdasigi/status/1019088389079949317?ref_src=twsrc%5Etfw">July 17, 2018</a></blockquote>
</amp-twitter>

<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1018753935849525248">
    <blockquote placeholder><p lang="en" dir="ltr">Slides for my talk available here:<a href="https://t.co/OclMGUZfp6">https://t.co/OclMGUZfp6</a><br>Discussed our work on explainable machine teaching and teaching forgetful learners. <a href="https://t.co/9Akl2nAnRD">https://t.co/9Akl2nAnRD</a></p>&mdash; Yisong Yue (@yisongyue) <a href="https://twitter.com/yisongyue/status/1018753935849525248?ref_src=twsrc%5Etfw">July 16, 2018</a></blockquote>
</amp-twitter>

<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1018883413355290625">
    <blockquote placeholder><p lang="en" dir="ltr">Wrote basic logistic regression tutorial <a href="https://t.co/C0WMAHa3lO">https://t.co/C0WMAHa3lO</a> using my own nn library. feedback appreciated. <a href="https://twitter.com/hashtag/MachineLearning?src=hash&amp;ref_src=twsrc%5Etfw">#MachineLearning</a> <br>Also, matplotlib rocks: <a href="https://t.co/Ods6TAQf9E">pic.twitter.com/Ods6TAQf9E</a></p>&mdash; harshvardhan Gupta (@harvey_slash) <a href="https://twitter.com/harvey_slash/status/1018883413355290625?ref_src=twsrc%5Etfw">July 16, 2018</a></blockquote>
</amp-twitter>

<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1018286970282397696">
    <blockquote placeholder><p lang="en" dir="ltr">I just found “Intro to AI” _very_ nicely drawn video course by Dan Klein and <a href="https://twitter.com/pabbeel?ref_src=twsrc%5Etfw">@pabbeel</a>. This is _really_ eyes and brain candies! I cannot wait to dig in and learn how to be a better teacher!!! *feels absolutely excited* <a href="https://t.co/jq78usCdDp">https://t.co/jq78usCdDp</a><br>A few drawings from the MDP section. <a href="https://t.co/K3Xo68uq3X">pic.twitter.com/K3Xo68uq3X</a></p>&mdash; Alf (冷在) (@AlfredoCanziani) <a href="https://twitter.com/AlfredoCanziani/status/1018286970282397696?ref_src=twsrc%5Etfw">July 15, 2018</a></blockquote>
</amp-twitter>

## Visualization
<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1018863807773446145">
    <blockquote placeholder><p lang="en" dir="ltr">America is the world&#39;s largest weapons exporter. I was curious to see what this looks like over time, so I mapped the flows of arms transfers leaving the U.S. from 1950 to 2017. The data comes from <a href="https://twitter.com/SIPRIorg?ref_src=twsrc%5Etfw">@SIPRIorg</a> &#39;s Arms Transfers Database. Full video here: <a href="https://t.co/5h1I6B2Xlp">https://t.co/5h1I6B2Xlp</a> <a href="https://t.co/WlSW73ZbLT">pic.twitter.com/WlSW73ZbLT</a></p>&mdash; Will Geary (@wgeary) <a href="https://twitter.com/wgeary/status/1018863807773446145?ref_src=twsrc%5Etfw">July 16, 2018</a></blockquote>
</amp-twitter>

<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1019042028921876480">
    <blockquote placeholder><p lang="en" dir="ltr">It&#39;s been 10 days since <a href="https://twitter.com/realDonaldTrump?ref_src=twsrc%5Etfw">@realDonaldTrump</a>&#39;s tariffs dropped. To celebrate, we at <a href="https://twitter.com/MacroPoloChina?ref_src=twsrc%5Etfw">@MacroPoloChina</a> released the <a href="https://twitter.com/hashtag/ChinaFootprint?src=hash&amp;ref_src=twsrc%5Etfw">#ChinaFootprint</a>, an interactive data visualization of Chinese spending+investment on US soil. Enjoy! <a href="https://t.co/Gjv82sb1ZL">https://t.co/Gjv82sb1ZL</a> <a href="https://t.co/bYzzZEldit">pic.twitter.com/bYzzZEldit</a></p>&mdash; Matt Sheehan (@mattsheehan88) <a href="https://twitter.com/mattsheehan88/status/1019042028921876480?ref_src=twsrc%5Etfw">July 17, 2018</a></blockquote>
</amp-twitter>

## Miscellaneous
<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1018845208623054853">
    <blockquote placeholder><p lang="en" dir="ltr">Ouch: “prestigious institutions had on average 65% higher grant application success rates and 50% larger award sizes, whereas less-prestigious institutions produced 65% more publications and had a 35% higher citation impact per dollar of funding” <a href="https://t.co/zRQ9oX0xpR">https://t.co/zRQ9oX0xpR</a></p>&mdash; Björn Brembs (@brembs) <a href="https://twitter.com/brembs/status/1018845208623054853?ref_src=twsrc%5Etfw">July 16, 2018</a></blockquote>
</amp-twitter>

### Science and Engineering
<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1018394751488413697">
    <blockquote placeholder><p lang="en" dir="ltr">In the context of machine learning research, science and engineering are not distinct concepts. You don&#39;t do &quot;science&quot; by thinking very hard about platonic ML concepts and then publishing your thoughts. You do science by engineering systems that test small ideas, iteratively.</p>&mdash; François Chollet (@fchollet) <a href="https://twitter.com/fchollet/status/1018394751488413697?ref_src=twsrc%5Etfw">July 15, 2018</a></blockquote>
</amp-twitter>

<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1019065908810022912">
    <blockquote placeholder><p lang="en" dir="ltr">My contribution to the “science” vs engineering debate. I think papers should be about explaining reproducible ideas clearly, not about winning datascience competitions. (In the ideal world ;) it should be okay to sacrifice performance for clarity, simplicity and reproducibility. <a href="https://t.co/xiBIuspCys">https://t.co/xiBIuspCys</a></p>&mdash; hardmaru (@hardmaru) <a href="https://twitter.com/hardmaru/status/1019065908810022912?ref_src=twsrc%5Etfw">July 17, 2018</a></blockquote>
</amp-twitter>

<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1019087310196039685"
             data-conversation="none">
    <blockquote placeholder><p lang="en" dir="ltr">Not saying SOTA isn’t important, but for example a much simpler algorithm that gets say 85% on CIFAR-100, 60 PTB perplexity, or 900 for CarRacing-v0 is more useful than overly complicated methods that get 89%, 56 or 920, esp for adapting them for other completely different tasks.</p>&mdash; hardmaru (@hardmaru) <a href="https://twitter.com/hardmaru/status/1019087310196039685?ref_src=twsrc%5Etfw">July 17, 2018</a></blockquote>
</amp-twitter>

### Autopsy of a DL Paper
<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1017831767699423232">
    <blockquote placeholder><p lang="en" dir="ltr">Just read another one of a myriad of <a href="https://twitter.com/hashtag/DeepLearning?src=hash&amp;ref_src=twsrc%5Etfw">#DeepLearning</a> papers and realized that the authors are reporting trivia, but covering it up with an obscene amount of deep learning fluff and burned GPU time... I shall tear it apart in my next blog post. Stay tuned.</p>&mdash; Filip Piekniewski (@filippie509) <a href="https://twitter.com/filippie509/status/1017831767699423232?ref_src=twsrc%5Etfw">July 13, 2018</a></blockquote>
</amp-twitter>

<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1018291609446649856">
    <blockquote placeholder><p lang="en" dir="ltr">OK, as promised here is a small autopsy of a paper I recently came across: <a href="https://t.co/uv7Vm0W4YX">https://t.co/uv7Vm0W4YX</a> <a href="https://twitter.com/hashtag/Deeplearning?src=hash&amp;ref_src=twsrc%5Etfw">#Deeplearning</a> <a href="https://twitter.com/hashtag/AI?src=hash&amp;ref_src=twsrc%5Etfw">#AI</a> <a href="https://t.co/6d0GafR84q">https://t.co/6d0GafR84q</a></p>&mdash; Filip Piekniewski (@filippie509) <a href="https://twitter.com/filippie509/status/1018291609446649856?ref_src=twsrc%5Etfw">July 15, 2018</a></blockquote>
</amp-twitter>

<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1018789622103633921">
    <blockquote placeholder><p lang="en" dir="ltr">So true, unfortunately. In NLP, people have been adding position features to embeddings for a long time. I don’t think anyone has managed to write a whole paper about a one-line feature to make it sound academic. <a href="https://t.co/cb9AsRZWMO">https://t.co/cb9AsRZWMO</a></p>&mdash; Denny Britz (@dennybritz) <a href="https://twitter.com/dennybritz/status/1018789622103633921?ref_src=twsrc%5Etfw">July 16, 2018</a></blockquote>
</amp-twitter>

<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1018790474927214592"
             data-conversation="none">
    <blockquote placeholder><p lang="en" dir="ltr">I really enjoyed the paper presentation, but the TLDR basically is: If your task cares about absolute positions it makes sense to add a position feature to your input! Do we need a paper for this?</p>&mdash; Denny Britz (@dennybritz) <a href="https://twitter.com/dennybritz/status/1018790474927214592?ref_src=twsrc%5Etfw">July 16, 2018</a></blockquote>
</amp-twitter>

## Tools
### Seaborn 0.9
<amp-twitter width="400" height="400"
             layout="responsive"
             data-tweetid="1018980107397091329">
    <blockquote placeholder><p lang="en" dir="ltr">seaborn 0.9 is out! New plots, better aesthetics, improved documentation, and other novelties here: <a href="https://t.co/6FqFvVUBPh">https://t.co/6FqFvVUBPh</a> <a href="https://t.co/AWqYZFGh3k">pic.twitter.com/AWqYZFGh3k</a></p>&mdash; Michael Waskom (@michaelwaskom) <a href="https://twitter.com/michaelwaskom/status/1018980107397091329?ref_src=twsrc%5Etfw">July 16, 2018</a></blockquote>
</amp-twitter>
